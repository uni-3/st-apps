{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "herbal-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib.robotparser\n",
    "from dataclasses import dataclass\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "metric-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-function",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "silver-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/0000177221_00008.html\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "departmental-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Scraper:\n",
    "    start_url: str\n",
    "    target_url: str\n",
    "    crawl_delay: int = 10\n",
    "        \n",
    "    def get_domain(self):\n",
    "        u = urllib.parse.urlsplit(self.target_url)\n",
    "        return f\"{u.scheme}://{u.hostname}\"\n",
    "\n",
    "    def url_can_fetch(self, robots_file=\"robots.txt\"):\n",
    "        rp = urllib.robotparser.RobotFileParser()\n",
    "        # /をつけてjoinするとurlのpath、query stringがなくなる\n",
    "        rp.set_url(urllib.parse.urljoin(self.target_url, \"/\", robots_file))\n",
    "        rp.read()\n",
    "\n",
    "        if rp.crawl_delay(\"*\") is not None:\n",
    "            self.crawl_delay = rp.crawl_delay(\"*\")\n",
    "\n",
    "        return rp.can_fetch(\"*\", self.target_url)\n",
    "\n",
    "    def request(self, url=None):\n",
    "        \"\"\"\n",
    "        https://qiita.com/hoto17296/items/8fcf55cc6cd823a18217\n",
    "        \"\"\"\n",
    "        if url is None:\n",
    "            url = self.target_url\n",
    "        req = urllib.request.Request(url)\n",
    "        try:\n",
    "            with urllib.request.urlopen(req) as res:\n",
    "                body = res.read()\n",
    "\n",
    "        except urllib.error.HTTPError as e:\n",
    "            print(e.code, url)\n",
    "        except urllib.error.URLError as e:\n",
    "            print(e.reason, url)\n",
    "\n",
    "        return body\n",
    "\n",
    "    def parse(self, body=None):\n",
    "        if body is None:\n",
    "            body = self.request()\n",
    "        soup = BeautifulSoup(body, \"html.parser\")\n",
    "\n",
    "        # TODO: if exist next url, request next url\n",
    "\n",
    "        return soup\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "talented-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Scraper(url, url)\n",
    "soup = s.parse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "brief-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "invisible-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 適当にh4のタイトル等つなげて出力\n",
    "l = []\n",
    "not_h4 = ['歯科傷病', '歯科傷病', '特定健診', '特定健診（質問票）', '二次医療圏別']\n",
    "\n",
    "for a in soup.find_all(\"a\", attrs={\"href\": re.compile(\".xlsx$\")}):\n",
    "    #print(a.string)\n",
    "    h3 = a.find_all_previous(\"h3\")\n",
    "    h4 = a.find_all_previous(\"h4\")\n",
    "    h3s = h3[0].string\n",
    "    h4s = h4[0].string\n",
    "    #print(h3, h4)\n",
    "    #print(h3[0].string, h4[0].string, a.string)\n",
    "    if h3s in not_h4:\n",
    "        h4s = \"\"\n",
    "    if a.string is not None:\n",
    "        l.append([\n",
    "            h3s + \" \" + h4s + \" \" + a.string,\n",
    "            s.get_domain() + a.get('href')\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "beneficial-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "unusual-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(l, columns=['title', 'url'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "distant-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataset/urls.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "unavailable-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# urlのみ\n",
    "a_tags = soup.find_all(\"a\", attrs={\"href\": re.compile(\".xlsx$\")})\n",
    "len(a_tags)\n",
    "df = pd.DataFrame()\n",
    "l = []\n",
    "for a in a_tags:\n",
    "    l.append([\n",
    "        a.string,\n",
    "        s.get_domain() + a.get('href')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "decimal-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>初再診料_性年齢別算定回数</td>\n",
       "      <td>https://www.mhlw.go.jp/content/12400000/000539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>初再診料_都道府県別算定回数</td>\n",
       "      <td>https://www.mhlw.go.jp/content/12400000/000539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>短期滞在手術等基本料_性年齢別算定回数</td>\n",
       "      <td>https://www.mhlw.go.jp/content/12400000/000539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>短期滞在手術等基本料_都道府県別算定回数</td>\n",
       "      <td>https://www.mhlw.go.jp/content/12400000/000539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>特定入院料_性年齢別算定回数</td>\n",
       "      <td>https://www.mhlw.go.jp/content/12400000/000539...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                                url\n",
       "0         初再診料_性年齢別算定回数  https://www.mhlw.go.jp/content/12400000/000539...\n",
       "1        初再診料_都道府県別算定回数  https://www.mhlw.go.jp/content/12400000/000539...\n",
       "2   短期滞在手術等基本料_性年齢別算定回数  https://www.mhlw.go.jp/content/12400000/000539...\n",
       "3  短期滞在手術等基本料_都道府県別算定回数  https://www.mhlw.go.jp/content/12400000/000539...\n",
       "4        特定入院料_性年齢別算定回数  https://www.mhlw.go.jp/content/12400000/000539..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(l, columns=['title', 'url'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "after-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../urls.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-electron",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
